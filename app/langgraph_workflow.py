from typing import Dict, TypedDict, Annotated, Sequence, List, Optional, Literal, Union, Any
import os, sys, json, logging, tempfile, shutil, subprocess, time, re, ast, contextlib, io, builtins
from langgraph.prebuilt import ToolNode
from langgraph_codeact import create_codeact
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import os
import sys
import tempfile
import shutil
import subprocess
import logging
import json
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å®šä¹‰çŠ¶æ€ç±»å‹
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], "æ¶ˆæ¯å†å²"]
    file_path: Optional[str]
    file_content: Optional[str]
    file_type: Optional[str]
    code_to_execute: Optional[str]
    execution_result: Optional[str]
    intermediate_steps: List[Dict[str, Any]]
    current_step: int
    max_iterations: int
    action: Optional[str]
    action_input: Optional[Union[Dict[str, Any], str]]
    observation: Optional[str]
    is_done: bool

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(model=os.getenv("OPENAI_MODEL_NAME", "gpt-4o"), temperature=0)

# å®šä¹‰å·¥å…·å‡½æ•°
def read_file_content(
    file_path: str,
    max_preview_lines: int = 10,
    max_preview_chars: int = 4000,
) -> str:
    """Read file content preview: binary files report length, text files return truncated preview."""
    binary_exts = {'.xlsx', '.xls', '.xlsb', '.xlsm', '.parquet', '.feather'}
    try:
        ext = os.path.splitext(file_path)[1].lower()
    except Exception:
        ext = ''

    if ext in binary_exts:
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            logger.info(f"Read binary file: {file_path}")
            return f"[binary file, length: {len(data)} bytes]"
        except Exception as e:
            logger.error(f"Failed to read binary file: {e}")
            return f"Failed to read file: {e}"

    encodings = ['utf-8', 'gbk', 'cp936', 'gb18030', 'latin1']
    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as file:
                content_parts: List[str] = []
                total_chars = 0
                line_count = 0
                line_limit_reached = False
                char_limit_reached = False

                while True:
                    line = file.readline()
                    if line == '':
                        break

                    content_parts.append(line)
                    total_chars += len(line)
                    line_count += 1

                    if total_chars >= max_preview_chars:
                        char_limit_reached = True
                        break
                    if line_count >= max_preview_lines:
                        line_limit_reached = True
                        break

                truncated = False
                if char_limit_reached:
                    truncated = True
                elif line_limit_reached:
                    extra = file.read(1)
                    if extra:
                        truncated = True

                preview = ''.join(content_parts)
                if len(preview) > max_preview_chars:
                    preview = preview[:max_preview_chars]
                    truncated = True

                if truncated:
                    preview = preview[:max_preview_chars].rstrip('\n')
                    preview += f"\n... (preview truncated to {line_count} lines and approximately {len(preview)} characters)"

                logger.info(
                    f"Loaded preview with encoding {encoding}: {file_path} (lines: {line_count}, chars: {len(preview)})"
                )
                return preview
        except UnicodeDecodeError:
            continue
        except Exception as e:
            logger.error(f"Failed to read file: {e}")
            return f"Failed to read file: {e}"

    # If all encodings fail, fall back to binary read
    try:
        with open(file_path, 'rb') as file:
            binary_content = file.read()
        logger.warning(f"Fallback to binary read: {file_path}")
        return f"[binary file, length: {len(binary_content)} bytes]"
    except Exception as e:
        logger.error(f"Failed to read file: {e}")
        return f"Failed to read file: {e}"

def detect_file_type(file_path):
    """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
    if file_path:
        extension = os.path.splitext(file_path)[1].lower()
        if extension in ['.csv', '.xlsx', '.xls']:
            return 'data'
        elif extension in ['.py']:
            return 'python'
        elif extension in ['.js', '.ts']:
            return 'javascript'
        elif extension in ['.json']:
            return 'json'
        elif extension in ['.txt', '.md']:
            return 'text'
    return 'unknown'

# ReAct Agent æ ¸å¿ƒé€»è¾‘
def react_agent_node(state: AgentState) -> AgentState:
    """ReAct Agent çš„æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯"""
    # å¦‚æœå·²ç»å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç›´æ¥è¿”å›
    if state.get("is_done", False) or state.get("current_step", 0) >= state.get("max_iterations", 5):
        state["is_done"] = True
        
        # ç¡®ä¿ç”Ÿæˆæœ€ç»ˆå›å¤
        if not any(isinstance(msg, AIMessage) for msg in state["messages"]):
            ai_message = AIMessage(content=f"å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {state.get('max_iterations', 5)}ï¼Œæ— æ³•ç»§ç»­å¤„ç†ã€‚è¯·æ£€æŸ¥æ‚¨çš„è¯·æ±‚æˆ–å°è¯•ç®€åŒ–ä»»åŠ¡ã€‚")
            messages = list(state["messages"])
            messages.append(ai_message)
            state["messages"] = messages
            
        return state
    
    # æ„å»ºæç¤º
    messages = list(state["messages"])
    
    # æ·»åŠ æ–‡ä»¶ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    file_info = ""
    if state.get("file_path"):
        file_path = state["file_path"]
        file_type = state.get("file_type") or detect_file_type(file_path)
        file_content = state.get("file_content")
        
        if not file_content and os.path.exists(file_path):
            file_content = read_file_content(file_path)
            state["file_content"] = file_content
            state["file_type"] = file_type
        
        if file_content:
            file_info = f"æ–‡ä»¶è·¯å¾„: {file_path}\næ–‡ä»¶ç±»å‹: {file_type}\næ–‡ä»¶å†…å®¹:\n{file_content}\n"
    
    # æ·»åŠ ä¸­é—´æ­¥éª¤å†å²
    steps_history = ""
    if state.get("intermediate_steps"):
        for i, step in enumerate(state["intermediate_steps"]):
            thought = step.get("thought", "")
            action = step.get("action", "")
            action_input = step.get("action_input")
            observation = step.get("observation", "")

            if isinstance(action_input, dict):
                action_input_str = json.dumps(action_input, ensure_ascii=False)
            elif action_input is None:
                action_input_str = ""
            else:
                action_input_str = str(action_input)

            steps_history += f"æ­¥éª¤ {i+1}:\næ€è€ƒ: {thought}\nè¡ŒåŠ¨: {action}\nè¡ŒåŠ¨è¾“å…¥: {action_input_str}\nè§‚å¯Ÿ: {observation}\n\n"
    
    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œä½¿ç”¨ReActï¼ˆæ€è€ƒ-è¡ŒåŠ¨ï¼‰æ–¹æ³•è§£å†³é—®é¢˜ã€‚
ä½ å¯ä»¥è¿›è¡Œå¦‚ä¸‹è¡ŒåŠ¨ï¼Œä½†æ¯æ¬¡åªå¯é€‰å…¶ä¸€:
1. execute_code: æ‰§è¡Œç”Ÿæˆçš„ä»£ç å¹¶è·å–ç»“æœ
2. final_answer: ç”Ÿæˆæœ€ç»ˆå›å¤å†…å®¹å¹¶ç»“æŸå¯¹è¯

{file_info if file_info else ""}

{steps_history if steps_history else ""}

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿›è¡Œå›åº”ï¼š
'''
{{
  "thought": "åœ¨è¿™é‡Œåˆ†æé—®é¢˜ï¼Œåˆ¶å®šè®¡åˆ’ï¼Œå¹¶åæ€ã€‚",
  "action": {{
    "name": "è¡ŒåŠ¨åç§°ï¼ˆexecute_code æˆ– final_answerï¼‰",
    "input": "ä»…å½“è¡ŒåŠ¨åç§°ä¸º 'execute_code' æ—¶ï¼Œåœ¨æ­¤å¤„ç”Ÿæˆè¦æ‰§è¡Œçš„Pythonä»£ç ï¼›ä»…å½“è¡ŒåŠ¨åç§°ä¸º 'final_answer' æ—¶ï¼Œå½“ä½ æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œåœ¨æ­¤å¤„æä¾›æœ€ç»ˆçš„æ–‡å­—ç­”æ¡ˆã€‚"
  }}
}}
'''
è¯·æ³¨æ„ï¼š
- `action.input` å¯¹è±¡ä¸­ï¼Œå¿…é¡»æ ¹æ® `action.name` çš„å€¼æä¾›ä»£ç æˆ–è€…å›å¤å†…å®¹ã€‚
- ä½ çš„æ•´ä¸ªè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªå¯ä»¥è¢« `json.loads()` è§£æçš„ã€å•ä¸€çš„ã€åˆæ³•çš„JSONå¯¹è±¡ã€‚

\nä»£ç ç”Ÿæˆè¦æ±‚:
- ä½¿ç”¨ pandas/numpy ç­‰åº“å¤„ç†æ•°æ®æ—¶ï¼ŒåŠ¡å¿…ä½¿ç”¨ print æ‰“å°å…³é”®ç»“æœã€‚
- æ‰“å°è¡¨æ ¼/åºåˆ—å‰ï¼Œè®¾ç½®å®Œæ•´æ˜¾ç¤ºé€‰é¡¹: 
  - DataFrame/Series è¯·ä¼˜å…ˆä½¿ç”¨ to_string() æ‰“å°å®Œæ•´å†…å®¹ã€‚
  - numpy å¦‚éœ€æ‰“å°æ•°ç»„ï¼Œå¯è®¾ç½® threshold/edgeitems æ”¾å®½æ˜¾ç¤ºé™åˆ¶ã€‚
  - å¦‚æœè¯»å–äº†æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ state ä¸­æä¾›çš„è·¯å¾„ï¼Œé¿å…ç¡¬ç¼–ç å…¶å®ƒè·¯å¾„ã€‚
  - ç¡®ä¿ä»£ç å¯ç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–äº¤äº’è¾“å…¥ã€‚
- å½“ä½ éœ€è¦ç”Ÿæˆå›¾è¡¨ã€ç»˜å›¾æˆ–ä»»ä½•è§†è§‰åŒ–ç»“æœæ—¶ï¼Œä½ å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
  - ç¦æ­¢ç›´æ¥æ˜¾ç¤ºï¼šç»å¯¹ç¦æ­¢è°ƒç”¨ plt.show() æˆ–ä»»ä½•å…¶ä»–è¯•å›¾æ‰“å¼€å›¾å½¢ç•Œé¢çš„å‡½æ•°ã€‚ä½ çš„è¿è¡Œç¯å¢ƒæ˜¯æ— ç•Œé¢çš„æœåŠ¡å™¨ã€‚
  - ä¿å­˜ä¸ºæ–‡ä»¶ï¼šä½ å¿…é¡»å°†å›¾è¡¨ä¿å­˜ä¸º PNG æ ¼å¼çš„å›¾ç‰‡æ–‡ä»¶ã€‚æ–‡ä»¶åå¿…é¡»ä¿è¯å…¨å±€å”¯ä¸€æ€§ã€‚
  - ä¿å­˜ä½ç½®ï¼šå›¾è¡¨æ–‡ä»¶å¿…é¡»ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ data/plots ç›®å½•ä¸­ã€‚ä½ å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ PROJECT_ROOT è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ã€‚
  - ä¸­æ–‡å­—ä½“ï¼šä½¿ç”¨ä¸­æ–‡æ—¶ï¼Œå¿…é¡»è®¾ç½®å¾®è½¯é›…é»‘å­—ä½“ï¼š`plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']`ï¼Œ`plt.rcParams['axes.unicode_minus'] = False`
  - æ‰“å°è®¿é—®è·¯å¾„ï¼šæ–‡ä»¶ä¿å­˜æˆåŠŸåï¼Œä½ å¿…é¡»ç«‹å³å…³é—­å›¾è¡¨ (plt.close()) ä»¥é‡Šæ”¾å†…å­˜ï¼Œç„¶åä»¥ PLOT_PATH::./data/plots/ä½ çš„å”¯ä¸€æ–‡ä»¶å.png çš„ç²¾ç¡®æ ¼å¼ï¼Œæ‰“å°å‡ºè¯¥å›¾ç‰‡çš„è·¯å¾„ã€‚"""

    # è¿½åŠ æ›´ä¸¥æ ¼çš„åˆ†æå‡†åˆ™ï¼Œé¿å…å¯¹å¹´ä»½/æ—¶é—´/ç¼–å·åšä¸å¿…è¦çš„ç»Ÿè®¡
    # system_prompt += (
    #     "\nåˆ†æå‡†åˆ™ï¼ˆåŠ¡å¿…éµå®ˆï¼‰ï¼š\n"
    #     "1) å…ˆç”¨ df.head(2)ã€df.columnsã€df.dtypes æ£€æŸ¥åˆ—åä¸ç±»å‹ï¼Œå†å†³å®šåˆ†ææ–¹æ¡ˆã€‚\n"
    #     "2) é»˜è®¤ä¸å¯¹â€˜å¹´ä»½/æ—¶é—´/ç¼–å·ç±»â€™å­—æ®µåšå‡å€¼/æ ‡å‡†å·®ç»Ÿè®¡ã€‚ä»¥ä¸‹æ¨¡å¼è§†ä¸ºæ—¶é—´/ç¼–å·ï¼šåˆ—åå« year/date/time/æ—¥æœŸ/æ—¶é—´/å¹´ï¼›æˆ–çº¯æ•´æ•°ä¸”å–å€¼èŒƒå›´åƒå¹´ä»½ï¼ˆ1800-2100ï¼‰ï¼›æˆ–åˆ—åå« id/code/ç¼–å·ã€‚\n"
    #     "   - å¯¹è¿™ç±»åˆ—ï¼Œå¦‚éœ€æ±‡æ€»ä»…ç»™å‡ºå”¯ä¸€å€¼ä¸ªæ•°ã€æœ€å°/æœ€å¤§å€¼æˆ–æ—¶é—´èŒƒå›´ï¼›é™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚ï¼Œå¦åˆ™ä¸è¦æŠŠå®ƒä»¬å¹¶å…¥æ•´ä½“ describe ç»“æœã€‚\n"
    #     "3) ä»…å¯¹ä¸â€˜é¢ç§¯/æ•°é‡/é‡‘é¢/æ¯”ç‡/å˜åŒ–â€™ç­‰åº¦é‡ç›¸å…³çš„æ•°å€¼åˆ—åšç»Ÿè®¡ï¼›å¿…è¦æ—¶å°†å¯è§£ææ–‡æœ¬åˆ—è½¬ä¸ºæ•°å€¼ï¼ˆpd.to_numeric(errors='coerce')ï¼‰ã€‚\n"
    #     "4) çŒœåˆ—åå‰å…ˆæ‰“å°å€™é€‰åˆ—å¹¶è¯´æ˜é€‰æ‹©ä¾æ®ï¼Œå†è¿›è¡Œè®¡ç®—ã€‚\n"
    #     "5) è¾“å‡ºå›´ç»•æ´è§ï¼ˆè¶‹åŠ¿ã€å¼‚å¸¸ã€å¯¹æ¯”ï¼‰ï¼›è¡¨æ ¼è¿‡é•¿æ—¶å…ˆå±•ç¤ºç¤ºä¾‹å¹¶åœ¨æ€»ç»“ä¸­å½’çº³ç»“è®ºã€‚\n"
    # )
    
    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ¶ˆæ¯ç±»å‹ï¼‰
    messages.insert(0, SystemMessage(content=system_prompt))
    
    # è°ƒç”¨LLMè·å–å›åº”
    response = llm.invoke(messages)
    response_content = response.content
    logger.info(f"LLMå“åº”åŸæ–‡: {response_content[:500]}")
    
    # ç›´æ¥è§£æå¤§æ¨¡å‹è¿”å›çš„JSONæ ¼å¼å†…å®¹
    try:
        response_data = json.loads(response_content)
        thought = response_data.get("thought", "")
        action_obj = response_data.get("action", {})
        action = action_obj.get("name", "")
        action_input = action_obj.get("input")

        # å…¼å®¹æ—§é€»è¾‘ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºä»£ç æ‰§è¡Œæˆ–æœ€ç»ˆç­”æ¡ˆ
        normalized_action = (action or "").lower()
        if not normalized_action and isinstance(action_input, dict):
            if "code" in action_input:
                normalized_action = "execute_code"
            elif "answer" in action_input:
                normalized_action = "final_answer"
        is_final_answer = normalized_action == "final_answer"

        # çŠ¶æ€è®°å½•
        current_step = state.get("current_step", 0) + 1
        step_record = {
            "thought": thought,
            "action": action,
            "action_input": action_input,
            "observation": ""
        }

        intermediate_steps = state.get("intermediate_steps", [])
        intermediate_steps.append(step_record)
        state["current_step"] = current_step
        state["intermediate_steps"] = intermediate_steps
        state["action"] = action
        state["action_input"] = action_input
        state["thought"] = thought

        # ç»ˆæ­¢åˆ¤æ–­
        if is_final_answer:
            state["is_done"] = True
            if isinstance(action_input, str):
                answer_text = action_input
            elif isinstance(action_input, dict):
                answer_text = action_input.get("answer", "")
            else:
                answer_text = ""

            if answer_text:
                ai_message = AIMessage(content=answer_text)
                messages = list(state["messages"])
                messages.append(ai_message)
                state["messages"] = messages
                state["final_answer"] = answer_text
        elif not action:
            if isinstance(action_input, str):
                answer_text = action_input
            elif isinstance(action_input, dict):
                answer_text = action_input.get("answer", "")
            else:
                answer_text = ""

            if answer_text:
                ai_message = AIMessage(content=answer_text)
                messages = list(state["messages"])
                messages.append(ai_message)
                state["messages"] = messages
                state["final_answer"] = answer_text

    except Exception as e:
        logger.error(f"è§£æå¤§æ¨¡å‹JSONå›å¤å¤±è´¥: {e}ï¼ŒåŸå§‹å†…å®¹: {response_content[:100]}...")
        state["error"] = f"è§£æå¤§æ¨¡å‹JSONå›å¤å¤±è´¥: {e}"
        ai_message = AIMessage(content="AIå›å¤æ ¼å¼è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥å¤§æ¨¡å‹è¾“å‡ºã€‚")
        messages = list(state.get("messages", []))
        messages.append(ai_message)
        state["messages"] = messages

    return state

# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def agent_node(state: AgentState) -> AgentState:
    """ä»£ç†èŠ‚ç‚¹ï¼Œåˆ†æç”¨æˆ·æŒ‡ä»¤å¹¶å†³å®šä¸‹ä¸€æ­¥æ“ä½œ"""
    messages = state["messages"]
    file_path = state.get("file_path")
    
    # æ„å»ºæç¤º
    prompt = "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„æŒ‡ä»¤ï¼Œå¹¶å†³å®šæ˜¯å¦éœ€è¦ç”Ÿæˆä»£ç ã€‚"
    
    if file_path:
        prompt += f"\nç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶: {os.path.basename(file_path)}"
    
    # æ·»åŠ æç¤ºåˆ°æ¶ˆæ¯å†å²
    all_messages = messages + [HumanMessage(content=prompt)]
    
    # è°ƒç”¨LLM
    response = llm.invoke(all_messages)
    
    # æ›´æ–°çŠ¶æ€
    return {
        **state,
        "messages": messages + [response]
    }

# å®‰å…¨çš„ä»£ç æ‰§è¡Œæ²™ç®±
def safe_code_executor(code: str, _locals: dict[str, Any]) -> tuple[str, dict[str, Any]]:
    """å®‰å…¨æ‰§è¡Œä»£ç å¹¶è¿”å›ç»“æœå’Œæ–°å˜é‡"""
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    logger.info(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
    
    # ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„data/plotsç›®å½•å­˜åœ¨
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    plots_dir = os.path.join(project_root, "data", "plots")
    os.makedirs(plots_dir, exist_ok=True)
    logger.info(f"ç¡®ä¿é¡¹ç›®plotsç›®å½•å­˜åœ¨: {plots_dir}")
    
    try:
        # å­˜å‚¨æ‰§è¡Œå‰çš„å˜é‡é”®
        original_keys = set(_locals.keys())
        
        # å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¤åˆ¶åˆ°ä¸´æ—¶ç›®å½•
        if _locals.get("file_path") and os.path.exists(_locals["file_path"]):
            file_name = os.path.basename(_locals["file_path"])
            dest_path = os.path.join(temp_dir, file_name)
            shutil.copy2(_locals["file_path"], dest_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶ {_locals['file_path']} åˆ° {dest_path}")
        
        # å†™å…¥ä»£ç åˆ°ä¸´æ—¶æ–‡ä»¶
        code_file = os.path.join(temp_dir, "code_to_execute.py")
        with open(code_file, "w", encoding="utf-8") as f:
            f.write(code)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env["PYTHONIOENCODING"] = "utf-8"
        env["PROJECT_ROOT"] = project_root  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•ç¯å¢ƒå˜é‡
        
        # æ‰§è¡Œä»£ç ï¼Œè®¾ç½®è¶…æ—¶
        try:
            process = subprocess.Popen(
                [sys.executable, code_file],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=False,  # æ”¹ä¸ºäºŒè¿›åˆ¶æ¨¡å¼
                cwd=temp_dir,
                env=env
            )
            
            # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º30ç§’
            try:
                stdout_bytes, stderr_bytes = process.communicate(timeout=30)
                # ä½¿ç”¨utf-8è§£ç 
                stdout = stdout_bytes.decode('utf-8', errors='replace')
                stderr = stderr_bytes.decode('utf-8', errors='replace')
                execution_result = stdout
                if stderr:
                    execution_result += f"\né”™è¯¯è¾“å‡º:\n{stderr}"
                
            except subprocess.TimeoutExpired:
                process.kill()
                execution_result = "é”™è¯¯: ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰"
                
        except Exception as e:
            execution_result = f"ä»£ç æ‰§è¡Œé”™è¯¯: {str(e)}"
    
        # ç¡®å®šæ‰§è¡ŒæœŸé—´åˆ›å»ºçš„æ–°å˜é‡
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ— æ³•è·å–å­è¿›ç¨‹ä¸­åˆ›å»ºçš„å˜é‡ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå ä½ç¬¦
        # å®é™…ä½¿ç”¨æ—¶ï¼Œå¯èƒ½éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼ä¼ é€’å˜é‡
        new_keys = set(_locals.keys()) - original_keys
        new_vars = {key: _locals[key] for key in new_keys}
        
        return execution_result, new_vars
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(temp_dir)
            logger.info(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

def execute_code_node(state: AgentState) -> AgentState:
    """æ‰§è¡Œä»£ç èŠ‚ç‚¹"""
    code = state.get("code_to_execute")
    if not code:
        logger.warning("æ²¡æœ‰ä»£ç å¯æ‰§è¡Œ")
        if state.get("intermediate_steps") and len(state["intermediate_steps"]) > 0:
            state["intermediate_steps"][-1]["observation"] = "é”™è¯¯ï¼šæ²¡æœ‰ä»£ç å¯æ‰§è¡Œ"
        return state

    # ä½¿ç”¨å®‰å…¨æ²™ç®±æ‰§è¡Œä»£ç 
    execution_result, new_vars = safe_code_executor(state.get("code_to_execute") or code, state)
    
    # æ›´æ–°çŠ¶æ€
    state["execution_result"] = execution_result
    if state.get("intermediate_steps") and len(state["intermediate_steps"]) > 0:
        state["intermediate_steps"][-1]["observation"] = execution_result
    state["code_to_execute"] = None

    # å°†æ–°å˜é‡æ·»åŠ åˆ°çŠ¶æ€ä¸­
    for key, value in new_vars.items():
        state[key] = value
    
    return state

def final_answer_node(state: AgentState) -> AgentState:
    """ç”Ÿæˆæœ€ç»ˆå›ç­”"""
    action_input = state.get("action_input")
    if isinstance(action_input, str):
        answer = action_input
    elif isinstance(action_input, dict):
        answer = action_input.get("answer", "")
    else:
        answer = ""
    
    if answer:
        # åˆ›å»ºAIæ¶ˆæ¯
        ai_message = AIMessage(content=answer)
        messages = list(state["messages"])
        messages.append(ai_message)
        state["messages"] = messages
        # è®°å½•æœ€ç»ˆç­”æ¡ˆï¼Œä¾¿äºå‰ç«¯ç›´æ¥è¯»å–
        state["final_answer"] = answer
    else:
        # å¦‚æœæ²¡æœ‰æä¾›answerï¼Œç”Ÿæˆä¸€ä¸ªåŸºäºæ‰§è¡Œç»“æœçš„å›å¤
        execution_result = state.get("execution_result", "")
        if execution_result:
            ai_message = AIMessage(content=f"ä»£ç æ‰§è¡Œå®Œæˆï¼Œç»“æœå¦‚ä¸‹ï¼š\n\n{execution_result}")
            messages = list(state["messages"])
            messages.append(ai_message)
            state["messages"] = messages
    
    # æ ‡è®°å·¥ä½œæµå·²å®Œæˆ
    state["is_done"] = True
    
    return state

from langchain_core.tools import tool

# å®šä¹‰å·¥å…·å‡½æ•°
def define_tools():
    """å®šä¹‰å¯ç”¨å·¥å…·"""
    
    @tool
    def read_file(file_path: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        return read_file_content(file_path)
    
    @tool
    def detect_file_type(file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
        if file_path:
            extension = os.path.splitext(file_path)[1].lower()
            if extension in ['.csv', '.xlsx', '.xls']:
                return 'data'
            elif extension in ['.py']:
                return 'python'
            elif extension in ['.js', '.ts']:
                return 'javascript'
            elif extension in ['.html']:
                return 'html'
            elif extension in ['.css']:
                return 'css'
            elif extension in ['.json']:
                return 'json'
            elif extension in ['.md']:
                return 'markdown'
            elif extension in ['.txt']:
                return 'text'
        return 'unknown'
    
    @tool
    def get_file_info(state) -> str:
        """è·å–å½“å‰æ–‡ä»¶ä¿¡æ¯"""
        if state.get("file_path") and state.get("file_content") and state.get("file_type"):
            return f"æ–‡ä»¶è·¯å¾„: {state.get('file_path')}\næ–‡ä»¶ç±»å‹: {state.get('file_type')}\næ–‡ä»¶å†…å®¹: {state.get('file_content')[:500]}..."
        elif state.get("file_path"):
            return f"æ–‡ä»¶è·¯å¾„: {state.get('file_path')}\nä½†æ–‡ä»¶å†…å®¹æœªåŠ è½½"
        else:
            return "æ²¡æœ‰æ–‡ä»¶ä¿¡æ¯"
    
    return [read_file, detect_file_type, get_file_info]

# åˆ›å»ºCodeActå·¥ä½œæµ
def create_codeact_workflow(llm):
    """åˆ›å»ºCodeActå·¥ä½œæµ"""
    # å®šä¹‰å·¥å…·
    tools_list = define_tools()
    
    # åˆ›å»ºä»£ç æ‰§è¡Œå™¨
    code_act = create_codeact(llm, tools_list, safe_code_executor)
    
    # ç¼–è¯‘å·¥ä½œæµï¼ˆä¸ä½¿ç”¨checkpointerï¼‰
    return code_act.compile()

async def process_query_streaming(instruction: str, file_path: Optional[str] = None, history_messages: Optional[List[Dict]] = None):
    """æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œå®æ—¶è¿”å›æ¯ä¸€æ­¥çš„æ€è€ƒè¿‡ç¨‹"""
    import asyncio
    from typing import AsyncGenerator
    
    # åˆå§‹åŒ–å¯¹è¯æ¶ˆæ¯
    messages: List[BaseMessage] = []

    # å°†å†å²æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸­
    if history_messages and len(history_messages) > 0:
        for msg in history_messages:
            candidate_path = msg.get("filePath")
            if (not file_path) and candidate_path:
                is_blob_url = isinstance(candidate_path, str) and candidate_path.startswith("blob:")
                is_http_url = isinstance(candidate_path, str) and (candidate_path.startswith("http://") or candidate_path.startswith("https://"))
                looks_local = isinstance(candidate_path, str) and (os.path.isabs(candidate_path) and os.path.exists(candidate_path))
                if looks_local and (not is_blob_url) and (not is_http_url):
                    file_path = candidate_path
                    logger.info(f"ä»å†å²æ¶ˆæ¯å›æ”¶æœ¬åœ°æ–‡ä»¶è·¯å¾„: {file_path}")

            if msg.get("role") == "user":
                messages.append(HumanMessage(content=msg.get("content", "")))
            elif msg.get("role") == "assistant":
                messages.append(AIMessage(content=msg.get("content", "")))
            elif msg.get("role") == "system":
                messages.append(SystemMessage(content=msg.get("content", "")))

    # å°†æ–‡ä»¶ä¸Šä¸‹æ–‡æ³¨å…¥ä¸ºç³»ç»Ÿæ¶ˆæ¯
    if file_path and os.path.exists(file_path):
        try:
            file_name = os.path.basename(file_path)
            file_type = detect_file_type(file_path)
            system_message = (
                f"ä½ æœ‰ä¸€ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†:\n"
                f"æ–‡ä»¶å: {file_name}\n"
                f"æ–‡ä»¶ç±»å‹: {file_type}\n"
                f"æ–‡ä»¶è·¯å¾„: {file_path}")
            messages.append(SystemMessage(content=system_message))
            logger.info(f"æˆåŠŸæ·»åŠ æ–‡ä»¶ä¿¡æ¯åˆ°ç³»ç»Ÿæ¶ˆæ¯: {file_path}")
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append(HumanMessage(content=instruction))

    # åˆå§‹åŒ–çŠ¶æ€
    state: AgentState = {
        "messages": messages,
        "file_path": file_path,
        "file_content": None,
        "file_type": detect_file_type(file_path) if file_path and os.path.exists(file_path) else None,
        "code_to_execute": None,
        "execution_result": None,
        "intermediate_steps": [],
        "current_step": 0,
        "max_iterations": 10,
        "action": None,
        "action_input": None,
        "observation": None,
        "is_done": False,
    }

    try:
        # è¿­ä»£å¼ ReAct å›è·¯ï¼Œæ¯ä¸€æ­¥éƒ½æµå¼è¿”å›
        for iteration in range(state.get("max_iterations", 5)):
            # å‘é€æ­¥éª¤å¼€å§‹ä¿¡å·
            yield {
                "type": "step_start",
                "step": iteration + 1,
                "message": f"ğŸ¤” å¼€å§‹ç¬¬ {iteration + 1} æ­¥æ€è€ƒ..."
            }

            # 1) è®© Agent åˆ†æå¹¶ç»™å‡º"æ€è€ƒ/è¡ŒåŠ¨/è¡ŒåŠ¨è¾“å…¥"
            state = react_agent_node(state)
            
            # è·å–å½“å‰æ­¥éª¤ä¿¡æ¯
            current_step = state.get("intermediate_steps", [])[-1] if state.get("intermediate_steps") else {}
            thought = current_step.get("thought", "")
            action = current_step.get("action", "")
            action_input = current_step.get("action_input", {})

            # æµå¼è¿”å›æ€è€ƒè¿‡ç¨‹
            if thought:
                yield {
                    "type": "thought",
                    "step": iteration + 1,
                    "content": thought
                }

            # æµå¼è¿”å›è¡ŒåŠ¨
            if action:
                yield {
                    "type": "action",
                    "step": iteration + 1,
                    "action": action,
                    "action_input": action_input
                }

            action_text = (state.get("action") or "").lower().strip()
            normalized_action = re.sub(r"[^a-z_]+", "", action_text)

            # 2) æ ¹æ®è¡ŒåŠ¨æ‰§è¡Œ
            # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæˆï¼ˆåœ¨react_agent_nodeä¸­è®¾ç½®ï¼‰
            if state.get("is_done", False):
                # å¦‚æœæ²¡æœ‰è¡ŒåŠ¨æˆ–è€…æ˜¯final_answerï¼Œç›´æ¥è¿”å›æœ€ç»ˆç­”æ¡ˆ
                if not action_text or (normalized_action == "final_answer") or ("final_answer" in action_text):
                    # è·å–æœ€ç»ˆç­”æ¡ˆ
                    messages_out = state.get("messages", [])
                    ai_messages = [m for m in messages_out if isinstance(m, AIMessage)]
                    final_response = ai_messages[-1].content if ai_messages else "ä»»åŠ¡å·²å®Œæˆ"
                    
                    # è·å–æ‰€æœ‰å†å²æ‰§è¡Œç»“æœ
                    all_execution_results = []
                    for step in state.get("intermediate_steps", []):
                        if "observation" in step and step["observation"]:
                            all_execution_results.append(step["observation"])
                    
                    # è·å–æœ€è¿‘ä¸€æ¬¡çš„LLMæ€è€ƒå’Œä»£ç æ‰§è¡Œç»“æœ
                    last_thought = thought if thought else ""
                    
                    # è°ƒç”¨makeReportå‡½æ•°ç”ŸæˆæŠ¥å‘Šï¼Œå¹¶å°†å…¶ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                    try:
                        report_md = makeReport(last_thought, all_execution_results)
                        print(report_md) # debug
                        # è¾“å‡ºæŠ¥å‘Šä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                        yield {
                            "type": "final_answer",
                            "step": iteration + 1,
                            "content": report_md
                        }
                    except Exception as e:
                        logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
                        # å¦‚æœæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹çš„æœ€ç»ˆç­”æ¡ˆ
                        yield {
                            "type": "final_answer",
                            "step": iteration + 1,
                            "content": final_response
                        }
                    break

            # 2.1) æœ€ç»ˆå›ç­”
            if isinstance(action_input, str):
                answer_candidate = action_input.strip()
            elif isinstance(action_input, dict):
                answer_candidate = action_input.get("answer", "")
            else:
                answer_candidate = ""

            is_final_answer = (
                (normalized_action == "final_answer") or
                ("final_answer" in action_text) or
                (not action_text and answer_candidate)
            )
            if is_final_answer:
                state = final_answer_node(state)
                
                # è·å–æ‰€æœ‰å†å²æ‰§è¡Œç»“æœ
                all_execution_results = []
                for step in state.get("intermediate_steps", []):
                    if "observation" in step and step["observation"]:
                        all_execution_results.append(step["observation"])
                
                # è·å–æœ€è¿‘ä¸€æ¬¡çš„LLMæ€è€ƒå’Œä»£ç æ‰§è¡Œç»“æœ
                last_thought = thought if thought else ""
                
                # è°ƒç”¨makeReportå‡½æ•°ç”ŸæˆæŠ¥å‘Šï¼Œå¹¶å°†å…¶ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                try:
                    report_md = makeReport(last_thought, all_execution_results)
                    print(report_md) # debug
                    # è¾“å‡ºæŠ¥å‘Šä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                    yield {
                        "type": "final_answer",
                        "step": iteration + 1,
                        "content": report_md
                    }
                except Exception as e:
                    logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
                    # å¦‚æœæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹çš„æœ€ç»ˆç­”æ¡ˆ
                    final_answer = state.get("final_answer") or ""
                    if final_answer:
                        yield {
                            "type": "final_answer",
                            "step": iteration + 1,
                            "content": final_answer
                        }
                break

            # 2.2) åªä¿ç•™ execute_code ç›¸å…³åˆ¤æ–­
            if ("æ‰§è¡Œä»£ç " in action_text) or (normalized_action in ("execute_code",)) or ("execute_code" in action_text):
                # æµå¼æ˜¾ç¤ºä»£ç æ‰§è¡Œå¼€å§‹
                if isinstance(action_input, str):
                    code = action_input
                elif isinstance(action_input, dict):
                    code = action_input.get("code")
                else:
                    code = None
                if code:
                    state["code_to_execute"] = code
                    print(f"----------\n{code}\n----------")
                    yield {
                        "type": "code_execution_start",
                        "step": iteration + 1,
                        "code": code
                    }
                # æ‰§è¡Œä»£ç 
                state = execute_code_node(state)
                # æµå¼è¿”å›æ‰§è¡Œç»“æœ
                execution_result = state.get("execution_result") or "(æ— è¾“å‡º)"
                yield {
                    "type": "code_execution_result",
                    "step": iteration + 1,
                    "result": execution_result
                }
                # æ›´æ–°è§‚å¯Ÿç»“æœ
                if state.get("intermediate_steps") and len(state["intermediate_steps"]) > 0:
                    state["intermediate_steps"][-1]["observation"] = execution_result
                # æµå¼è¿”å›è§‚å¯Ÿ
                yield {
                    "type": "observation",
                    "step": iteration + 1,
                    "content": execution_result
                }
                # å°†æ‰§è¡Œç»“æœåé¦ˆä¸º"è§‚å¯Ÿ"ï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯
                state_messages = list(state["messages"])
                state_messages.append(HumanMessage(content=f"è§‚å¯Ÿ:\n{execution_result}\n\nè¯·æ ¹æ®è§‚å¯Ÿæ›´æ–°ä½ çš„è®¡åˆ’æˆ–ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚"))
                state["messages"] = state_messages
                continue

            # å…¶ä»–åŠ¨ä½œï¼Œç›´æ¥ç»§ç»­ä¸‹ä¸€è½®
            continue

        # å¦‚æœæ²¡æœ‰æœ€ç»ˆç­”æ¡ˆï¼Œç”Ÿæˆä¸€ä¸ªæ€»ç»“
        if not state.get("final_answer"):
            messages_out: List[BaseMessage] = state.get("messages", [])
            ai_messages = [m for m in messages_out if isinstance(m, AIMessage)]
            response_text = ai_messages[-1].content if ai_messages else f"æ”¶åˆ°æŒ‡ä»¤ï¼š'{instruction}'ã€‚"
            
            if state.get("execution_result"):
                if not response_text.endswith("\n"):
                    response_text += "\n\n"
                response_text += f"ä»£ç æ‰§è¡Œç»“æœï¼š\n\n{state.get('execution_result')}"

            yield {
                "type": "final_response",
                "content": response_text,
                "intermediate_steps": state.get("intermediate_steps", []),
                "execution_result": state.get("execution_result"),
                "file_path": state.get("file_path")
            }

    except Exception as e:
        logger.error(f"æµå¼å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
        yield {
            "type": "error",
            "message": f"å¤„ç†å¤±è´¥: {str(e)}"
        }

def makeReport(last_thought, all_execution_results):
    """
    ç”Ÿæˆä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹å’Œæ‰§è¡Œç»“æœ
    
    Args:
        last_thought (str): æœ€åä¸€æ¬¡LLMçš„æ€è€ƒå†…å®¹
        all_execution_results (list): æ‰€æœ‰å†å²æ­¥éª¤çš„æ‰§è¡Œç»“æœåˆ—è¡¨
        
    Returns:
        str: Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
    """
    # æç¤ºè¯æ¨¡æ¿
    prompt_template = """
    ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä»½Markdownæ ¼å¼çš„æŠ¥å‘Šï¼š
    å†å²åˆ†æè¿‡ç¨‹å¦‚ä¸‹
    {thought}
    å†å²ä»£ç æ‰§è¡Œç»“æœå¦‚ä¸‹
    {results}
    è¯·ç”Ÿæˆä¸€ä»½ç»“æ„æ¸…æ™°çš„MarkdownæŠ¥å‘Šï¼Œå¿…è¦æ—¶é™„å¸¦ä¸Šå›¾ç‰‡
    æ³¨æ„ï¼Œä½ åªéœ€è¦ä»¥Markdownæ ¼å¼çš„æ–‡æœ¬è¿”å›æŠ¥å‘Š,ä¸éœ€è¦ä»»ä½•è¯­æ³•çš„åŒ…è£¹ã€‚
    """
    
    try:
        # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä½¿ç”¨æ‰€æœ‰æ‰§è¡Œç»“æœ
        all_results_text = "\n\n".join([f"æ­¥éª¤ {i+1}:\n```\n{result}\n```" for i, result in enumerate(all_execution_results) if result])
        prompt = prompt_template.format(thought=last_thought, results=all_results_text)
        
        # è°ƒç”¨AIç”ŸæˆæŠ¥å‘Š
        return llm.invoke(prompt).content
    except Exception as e:
        logger.warning(f"ä½¿ç”¨å…¨éƒ¨æ‰§è¡Œç»“æœç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}ï¼Œå°è¯•ä½¿ç”¨ååŠéƒ¨åˆ†ç»“æœ")
        
        try:
            # ç¬¬äºŒæ¬¡å°è¯•ï¼šä½¿ç”¨ååŠéƒ¨åˆ†æ‰§è¡Œç»“æœ
            half_index = len(all_execution_results) // 2
            half_results = all_execution_results[half_index:]
            half_results_text = "\n\n".join([f"æ­¥éª¤ {i+half_index+1}:\n```\n{result}\n```" for i, result in enumerate(half_results) if result])
            prompt = prompt_template.format(thought=last_thought, results=half_results_text)
            
            # è°ƒç”¨AIç”ŸæˆæŠ¥å‘Š
            return llm.invoke(prompt).content
        except Exception as e:
            logger.warning(f"ä½¿ç”¨ååŠéƒ¨åˆ†æ‰§è¡Œç»“æœç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}ï¼Œå°è¯•ä»…ä½¿ç”¨æœ€åä¸€æ¬¡æ‰§è¡Œç»“æœ")
            
            try:
                # ç¬¬ä¸‰æ¬¡å°è¯•ï¼šä»…ä½¿ç”¨æœ€åä¸€æ¬¡æ‰§è¡Œç»“æœ
                if all_execution_results and len(all_execution_results) > 0:
                    last_result = all_execution_results[-1]
                    last_result_text = f"æœ€ç»ˆç»“æœ:\n```\n{last_result}\n```"
                    prompt = prompt_template.format(thought=last_thought, results=last_result_text)
                    
                    # è°ƒç”¨AIç”ŸæˆæŠ¥å‘Š
                    return llm.invoke(prompt).content
                else:
                    # æ²¡æœ‰æ‰§è¡Œç»“æœ
                    prompt = prompt_template.format(thought=last_thought, results="æ²¡æœ‰æ‰§è¡Œç»“æœã€‚")
                    return llm.invoke(prompt).content
            except Exception as e:
                logger.error(f"ç”ŸæˆæŠ¥å‘Šæœ€ç»ˆå¤±è´¥: {str(e)}")
                return f"# æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\nç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# def process_query(instruction: str, file_path: Optional[str] = None, history_messages: Optional[List[Dict]] = None) -> Dict:
#     """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼šç†è§£éœ€æ±‚â†’ç”Ÿæˆ/æ‰§è¡Œä»£ç â†’åŸºäºç»“æœå›ç­”ï¼ˆReAct å›è·¯ï¼‰"""
#     # åˆå§‹åŒ–å¯¹è¯æ¶ˆæ¯
#     messages: List[BaseMessage] = []

#     # å°†å†å²æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸­
#     if history_messages and len(history_messages) > 0:
#         # å°†å†å²æ¶ˆæ¯è½¬æ¢ä¸ºLangChainæ¶ˆæ¯æ ¼å¼
#         for msg in history_messages:
#             # å›æ”¶æ–‡ä»¶è·¯å¾„ï¼šä¼˜å…ˆä½¿ç”¨åŠ©æ‰‹æ¶ˆæ¯è¿”å›çš„çœŸå®æœ¬åœ°è·¯å¾„
#             candidate_path = msg.get("filePath")
#             if (not file_path) and candidate_path:
#                 # è¿‡æ»¤æ‰æµè§ˆå™¨çš„ blob: URL æˆ–éæœ¬åœ°ç»å¯¹è·¯å¾„ï¼Œé¿å…é”™è¯¯è·¯å¾„æ±¡æŸ“
#                 is_blob_url = isinstance(candidate_path, str) and candidate_path.startswith("blob:")
#                 is_http_url = isinstance(candidate_path, str) and (candidate_path.startswith("http://") or candidate_path.startswith("https://"))
#                 looks_local = isinstance(candidate_path, str) and (os.path.isabs(candidate_path) and os.path.exists(candidate_path))
#                 if looks_local and (not is_blob_url) and (not is_http_url):
#                     file_path = candidate_path
#                     logger.info(f"ä»å†å²æ¶ˆæ¯å›æ”¶æœ¬åœ°æ–‡ä»¶è·¯å¾„: {file_path}")
#                 else:
#                     # å¿½ç•¥éæœ¬åœ°/æ— æ•ˆè·¯å¾„
#                     pass

#             if msg.get("role") == "user":
#                 messages.append(HumanMessage(content=msg.get("content", "")))
#             elif msg.get("role") == "assistant":
#                 messages.append(AIMessage(content=msg.get("content", "")))
#             elif msg.get("role") == "system":
#                 messages.append(SystemMessage(content=msg.get("content", "")))

#     # å°†æ–‡ä»¶ä¸Šä¸‹æ–‡æ³¨å…¥ä¸ºç³»ç»Ÿæ¶ˆæ¯ï¼Œä¾¿äºæ¨¡å‹æ„ŸçŸ¥
#     file_content: Optional[str] = None
#     file_type: Optional[str] = None
#     if file_path and os.path.exists(file_path):
#         try:
#             file_name = os.path.basename(file_path)
#             file_type = detect_file_type(file_path)
#             # ä¸ç›´æ¥æ³¨å…¥äºŒè¿›åˆ¶å†…å®¹ï¼Œæ”¹ä¸ºæä¾›è·¯å¾„ä¸ç±»å‹
#             system_message = (
#                 f"ä½ æœ‰ä¸€ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†:\n"
#                 f"æ–‡ä»¶å: {file_name}\n"
#                 f"æ–‡ä»¶ç±»å‹: {file_type}\n"
#                 f"æ–‡ä»¶è·¯å¾„: {file_path}")
#             messages.append(SystemMessage(content=system_message))
#             logger.info(f"æˆåŠŸæ·»åŠ æ–‡ä»¶ä¿¡æ¯åˆ°ç³»ç»Ÿæ¶ˆæ¯: {file_path}")
#         except Exception as e:
#             logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

#     # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
#     messages.append(HumanMessage(content=instruction))

#     # åˆå§‹åŒ–çŠ¶æ€
#     state: AgentState = {
#         "messages": messages,
#         "file_path": file_path,
#         "file_content": None,
#         "file_type": detect_file_type(file_path) if file_path and os.path.exists(file_path) else None,
#         "code_to_execute": None,
#         "execution_result": None,
#         "intermediate_steps": [],
#         "current_step": 0,
#         "max_iterations": 10,
#         "action": None,
#         "action_input": None,
#         "observation": None,
#         "is_done": False,
#     }

#     try:
#         # è¿­ä»£å¼ ReAct å›è·¯
#         for _ in range(state.get("max_iterations", 5)):
#             # 1) è®© Agent åˆ†æå¹¶ç»™å‡º"æ€è€ƒ/è¡ŒåŠ¨/è¡ŒåŠ¨è¾“å…¥"
#             state = react_agent_node(state)

#             action_text = (state.get("action") or "").lower().strip()
#             # è§„èŒƒåŒ–è¡ŒåŠ¨æ ‡è®°ï¼Œå»æ‰æ‹¬å·/ç©ºæ ¼ç­‰ï¼Œå¦‚ "[final_answer]" â†’ "final_answer"
#             normalized_action = re.sub(r"[^a-z_]+", "", action_text)

#             # 2) æ ¹æ®è¡ŒåŠ¨æ‰§è¡Œ
#             if not action_text:
#                 # æ— è¡ŒåŠ¨ï¼Œç»§ç»­ä¸‹ä¸€è½®ï¼Œç›´åˆ°è¾¾åˆ°ä¸Šé™
#                 continue

#             # 2.1) æœ€ç»ˆå›ç­”
#             if (normalized_action == "final_answer") or ("final_answer" in action_text):
#                 state = final_answer_node(state)
#                 break

#             # 2.2) ç”Ÿæˆå¹¶/æˆ–æ‰§è¡Œä»£ç ï¼ˆä¸­æ–‡"æ‰§è¡Œä»£ç "æˆ–è‹±æ–‡ execute_codeï¼‰
#             if ("æ‰§è¡Œä»£ç " in action_text) or (normalized_action in ("execute_code", "generate_code")) or ("execute_code" in action_text) or ("generate_code" in action_text):
#                 # å¦‚æœä¸Šä¸€æ­¥ä» LLM æå–åˆ°äº†ä»£ç ï¼Œæ”¾å…¥å¾…æ‰§è¡Œ
#                 action_input = state.get("action_input") or {}
#                 code = action_input.get("code") if isinstance(action_input, dict) else None
#                 if code:
#                     state["code_to_execute"] = code
#                 # æ‰§è¡Œä»£ç 
#                 state = execute_code_node(state)

#                 # å°†æ‰§è¡Œç»“æœåé¦ˆä¸º"è§‚å¯Ÿ"ï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯
#                 observation_text = state.get("execution_result") or "(æ— è¾“å‡º)"
#                 state_messages = list(state["messages"])  # type: ignore
#                 state_messages.append(HumanMessage(content=f"è§‚å¯Ÿ:\n{observation_text}\n\nè¯·æ ¹æ®è§‚å¯Ÿæ›´æ–°ä½ çš„è®¡åˆ’æˆ–ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚"))
#                 state["messages"] = state_messages
#                 continue

#             # å…¶ä»–åŠ¨ä½œï¼Œç›´æ¥ç»§ç»­ä¸‹ä¸€è½®
#             continue

#         # ç»„ç»‡è¿”å›
#         messages_out: List[BaseMessage] = state.get("messages", [])  # type: ignore
#         intermediate_steps = state.get("intermediate_steps", [])

#         # å–æœ€åä¸€ä¸ª AI å›å¤ä½œä¸ºæ€»ä½“å›å¤
#         ai_messages = [m for m in messages_out if isinstance(m, AIMessage)]
#         response_text = ai_messages[-1].content if ai_messages else f"æ”¶åˆ°æŒ‡ä»¤ï¼š'{instruction}'ã€‚"

#         # å¦‚æœ‰æ‰§è¡Œç»“æœï¼Œé™„åŠ åˆ°å“åº”ï¼ˆå³ä½¿æœªæ˜¾å¼è§¦å‘ final_answer ä¹Ÿå±•ç¤ºï¼‰
#         if state.get("execution_result"):
#             if not response_text.endswith("\n"):
#                 response_text += "\n\n"
#             response_text += f"ä»£ç æ‰§è¡Œç»“æœï¼š\n\n{state.get('execution_result')}"

#         # å¦‚æœä»ç„¶æ²¡æœ‰å¯è¯»ä¿¡æ¯ï¼Œå›é€€å±•ç¤ºæœ€åä¸€æ­¥æ€è€ƒ/è¡ŒåŠ¨/è§‚å¯Ÿæ‘˜è¦
#         if (not ai_messages) and (not state.get("execution_result")):
#             last_step = intermediate_steps[-1] if intermediate_steps else None
#             if last_step:
#                 summary = (
#                     f"æ€è€ƒ: {last_step.get('thought', '')}\n"
#                     f"è¡ŒåŠ¨: {last_step.get('action', '')}\n"
#                     f"è§‚å¯Ÿ: {str(last_step.get('observation', ''))[:800]}"
#                 )
#                 if not response_text.endswith("\n"):
#                     response_text += "\n\n"
#                 response_text += summary

#         final_answer_val = state.get("final_answer")
#         return {
#             "response": final_answer_val or response_text,
#             "final_answer": final_answer_val,
#             "intermediate_steps": intermediate_steps,
#             "execution_result": state.get("execution_result"),
#             "file_path": state.get("file_path"),
#         }
#     except Exception as e:
#         logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
#         return {
#             "response": f"å¤„ç†å¤±è´¥: {str(e)}",
#             "intermediate_steps": [],
#             "execution_result": None,
#         }
